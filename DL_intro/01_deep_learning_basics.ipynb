{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"//fonts.googleapis.com/css?family=Quicksand:300\" />\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"custom.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"//fonts.googleapis.com/css?family=Quicksand:300\" />\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"custom.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning over the years\n",
    "\n",
    "![three_quarters center](images/dl_timeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deep Learning over the years\n",
    "\n",
    "- 1958 - Percentron unit - Frank Rosenblatt\n",
    "- **1986 - Backpropagation - Geoffrey Hinton**\n",
    "- 1986 - RNN - Schuster & Pallwal\n",
    "- 1989 - LeNet Backpropagation to multi-layer perceptron - Yan LeCun\n",
    "- 1997 - LSTM - Sepp Hochreiter and JÃ¼rgen Schmidhuber\n",
    "- **1998 - LeNet-5 Convolutional neural networks - YanLecun**\n",
    "- 2007 - Fei Fei Li Princeton ImageNet competition\n",
    "- 2009 - GPU for deep learning - Andrew Ng\n",
    "- **2011 - Demonstration of ReLu for deep neural networks - Yoshua Bengio**\n",
    "- **2012 - AlexNet wins ImageNet 25% to 16% error**\n",
    "- 2012 - Dropout technique - Geoffrey Hinton\n",
    "- **2014 - Generative adversarial networks - Ian Goodfellow & Yoshua Bengio**\n",
    "- **2015 - CNN beats human error in ImageNet 5% to 3%**\n",
    "- **2016 - AlphaGo - Goole DeepMind**\n",
    "- 2016 - Detectic metatastic cancer beats human pathologist .96 to 0.99 AUC\n",
    "- 2017 - Capsule networks - Geoffrey Hinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deep Learning over the years\n",
    "\n",
    "![three_quarters center](images/lecunn_quote.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neural Network\n",
    "\n",
    "\n",
    "![left half](images/neurons.jpg)\n",
    "![right half](images/dnn.png)\n",
    "\n",
    "&nbsp;\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Neuron description\n",
    "\n",
    "![neuron_comparison center half](images/neuron_comparison.png)\n",
    "\n",
    "Frist artificial neuron proposed in 1943!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neural Networks - Components\n",
    "\n",
    "![dnn center half](images/dnn_labels.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Artificial neuron\n",
    "\n",
    "![artificial_neuron center half](images/artificial_neuron.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Layers\n",
    "\n",
    "Hierarchical feature representations\n",
    "\n",
    "![layers center](images/layers.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![neural_networks_collection](images/neural_networks_collection.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Typical training flow\n",
    "\n",
    "\n",
    "![center half](images/model_diagram.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward pass\n",
    "\n",
    "![center half](images/forward_pass_0.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward pass\n",
    "\n",
    "\n",
    "![center half](images/forward_pass_1.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward pass\n",
    "\n",
    "\n",
    "![center half](images/forward_pass_2.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_0.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_1.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_2.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "\n",
    "\n",
    "![center half](images/backpropagation_3.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Optimization by backpropagation\n",
    "\n",
    "1. Loss/cost function\n",
    "2. Gradient descent\n",
    " 1. Stochastic gradient descent (SGD)\n",
    " 2. SGD + momentum\n",
    " 3. SGD + Nesterov\n",
    " 4. AdaGrad\n",
    " 5. RMSProp\n",
    " 6. Adam\n",
    " 7. Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Optimizers\n",
    "\n",
    "![optimizers_1 left half](images/optimizers_1.gif)\n",
    "![optimizers_2 right half](images/optimizers_2.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When to use neural nets?\n",
    "\n",
    "** Data types**\n",
    "\n",
    "- **Structured data**\n",
    "    - Handcrafted feature engineering\n",
    "    - Boosting algoritms\n",
    "\n",
    "- **Unstructured data** \n",
    "    - (images/text/signals) use neural networks and deep learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# When to use neural nets?\n",
    "\n",
    "**Dataset size**\n",
    "\n",
    "To cite the [Deep Learning](http://www.deeplearningbook.org/contents/intro.html) book:\n",
    "\n",
    ">  As of 2016, a rough rule of thumb is that a supervised deep learning algorithm will generally achieve acceptable performance with around 5,000 labeled examples per category, and will match or exceed human performance when trained with a dataset containing at least 10 million labeled examples. Working successfully with datasets smaller than this is an important research area, focusing in particular on how we can take advantage of large quantities of unlabeled examples, with unsupervised or semi-supervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Next: Deep learning tools](02_deep_learning_tools.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
